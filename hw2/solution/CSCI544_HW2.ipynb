{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipython-autotime\n",
      "  Downloading ipython_autotime-0.3.1-py2.py3-none-any.whl (6.8 kB)\n",
      "Requirement already satisfied: ipython in c:\\binaries\\python_envs\\csci544\\lib\\site-packages (from ipython-autotime) (8.15.0)\n",
      "Requirement already satisfied: backcall in c:\\binaries\\python_envs\\csci544\\lib\\site-packages (from ipython->ipython-autotime) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\binaries\\python_envs\\csci544\\lib\\site-packages (from ipython->ipython-autotime) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\binaries\\python_envs\\csci544\\lib\\site-packages (from ipython->ipython-autotime) (0.19.0)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\binaries\\python_envs\\csci544\\lib\\site-packages (from ipython->ipython-autotime) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in c:\\binaries\\python_envs\\csci544\\lib\\site-packages (from ipython->ipython-autotime) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\binaries\\python_envs\\csci544\\lib\\site-packages (from ipython->ipython-autotime) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\binaries\\python_envs\\csci544\\lib\\site-packages (from ipython->ipython-autotime) (2.16.1)\n",
      "Requirement already satisfied: stack-data in c:\\binaries\\python_envs\\csci544\\lib\\site-packages (from ipython->ipython-autotime) (0.6.2)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\binaries\\python_envs\\csci544\\lib\\site-packages (from ipython->ipython-autotime) (5.10.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\binaries\\python_envs\\csci544\\lib\\site-packages (from ipython->ipython-autotime) (1.1.3)\n",
      "Requirement already satisfied: colorama in c:\\binaries\\python_envs\\csci544\\lib\\site-packages (from ipython->ipython-autotime) (0.4.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\binaries\\python_envs\\csci544\\lib\\site-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\binaries\\python_envs\\csci544\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython->ipython-autotime) (0.2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\binaries\\python_envs\\csci544\\lib\\site-packages (from stack-data->ipython->ipython-autotime) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\binaries\\python_envs\\csci544\\lib\\site-packages (from stack-data->ipython->ipython-autotime) (2.4.0)\n",
      "Requirement already satisfied: pure-eval in c:\\binaries\\python_envs\\csci544\\lib\\site-packages (from stack-data->ipython->ipython-autotime) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\binaries\\python_envs\\csci544\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython->ipython-autotime) (1.16.0)\n",
      "Installing collected packages: ipython-autotime\n",
      "Successfully installed ipython-autotime-0.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install ipython-autotime\n",
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2023-09-21 21:48:04 -07:00)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2023-09-21 21:48:05 -07:00)\n"
     ]
    }
   ],
   "source": [
    "class PathConfig:\n",
    "    HW2_DIR = os.path.dirname(os.getcwd())\n",
    "    OUTPUT_DIR = os.path.join(HW2_DIR, \"solution\", \"output\")\n",
    "\n",
    "    DATA_PATH = os.path.join(HW2_DIR, \"CSCI544_HW2/data\")\n",
    "    VERIFICATION_DATA_PATH = os.path.join(HW2_DIR, \"CSCI544_HW2/verification\")\n",
    "\n",
    "    VOCAB_FILE_PATH = os.path.join(OUTPUT_DIR, \"vocab.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15 ms (started: 2023-09-21 21:48:06 -07:00)\n"
     ]
    }
   ],
   "source": [
    "class VocabConfig:\n",
    "    UNKNOWN_TOKEN = \"<unk>\"\n",
    "    THRESHOLD = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Vocabulary Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>,</td>\n",
       "      <td>46476</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>42044</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>39533</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.</td>\n",
       "      <td>37452</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of</td>\n",
       "      <td>22104</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>to</td>\n",
       "      <td>21305</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a</td>\n",
       "      <td>18469</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>and</td>\n",
       "      <td>15346</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>in</td>\n",
       "      <td>14609</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>'s</td>\n",
       "      <td>8872</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Word  Frequency  Index\n",
       "0      ,      46476      0\n",
       "1  <unk>      42044      1\n",
       "2    the      39533      2\n",
       "3      .      37452      3\n",
       "4     of      22104      4\n",
       "5     to      21305      5\n",
       "6      a      18469      6\n",
       "7    and      15346      7\n",
       "8     in      14609      8\n",
       "9     's       8872      9"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.28 s (started: 2023-09-22 01:53:26 -07:00)\n"
     ]
    }
   ],
   "source": [
    "class VocabularyGenerator:\n",
    "    def __init__(self, threshold: int, unknown_token: str = None, save: bool = True, path: str = None):\n",
    "        \"\"\"Initialize a VocabularyGenerator\n",
    "\n",
    "        Args:\n",
    "            threshold (int): Frequency threshold for rare words.\n",
    "            unknown_token (str, optional): Token to replace rare words. Defaults to None.\n",
    "            save (bool, optional): Flag to save the vocabulary. Default is True.\n",
    "            path (str, optional): Path to save the vocabulary. Defaults to None.\n",
    "\n",
    "        Usage:\n",
    "            vocab_generator = VocabularyGenerator(threshold=3, unknown_token=\"<unk>\")\n",
    "            vocab_df = vocab_generator.generate_vocabulary(data, \"sentence\")\n",
    "        \"\"\"\n",
    "        self.threshold = threshold\n",
    "        self.unknown_token = (\n",
    "            unknown_token if unknown_token is not None else VocabConfig.UNKNOWN_TOKEN\n",
    "        )\n",
    "        self._save = save\n",
    "\n",
    "        if self._save and path is None:\n",
    "            self._path = PathConfig.VOCAB_FILE_PATH\n",
    "            \n",
    "        self.path = path\n",
    "\n",
    "    def _count_word_frequency(self, data, sentence_col_name):\n",
    "        word_freq = data[sentence_col_name].apply(lambda sentence: Counter(sentence))\n",
    "\n",
    "        # Initialize an empty counter\n",
    "        combined_counter = Counter()\n",
    "        # Loop through each counter and update the combined counter\n",
    "        for counter in word_freq:\n",
    "            combined_counter.update(counter)\n",
    "\n",
    "        # Convert combined_counter to a list of tuples (word, frequency)\n",
    "        return combined_counter.items()\n",
    "    \n",
    "    def generate_vocabulary(self, data: pd.DataFrame, sentence_col_name: str):\n",
    "        \"\"\"Generate a vocabulary from the provided dataset.\n",
    "\n",
    "        Args:\n",
    "            data (pd.DataFrame): The DataFrame containing the dataset.\n",
    "            sentence_col_name (str): The name of the column containing sentences.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame with the generated vocabulary.\n",
    "\n",
    "        This method takes a DataFrame with sentences and generates a vocabulary based on word frequencies.\n",
    "        It replaces words with frequencies less than the specified threshold with the unknown token (\"<unk>\").\n",
    "        The resulting DataFrame is sorted by frequency and indexed.\n",
    "\n",
    "        If the 'save' flag is set, the vocabulary will be saved to the specified path.\n",
    "\n",
    "        Usage:\n",
    "            ```py\n",
    "            vocab_generator = VocabularyGenerator(threshold=3, unknown_token=\"<unk>\")\n",
    "            vocab_df = vocab_generator.generate_vocabulary(data, sentence_col_name)\n",
    "            ```\n",
    "        \"\"\"\n",
    "        word_freq_list = self._count_word_frequency(data, sentence_col_name)\n",
    "\n",
    "        # Create a DataFrame\n",
    "        word_freq_df = pd.DataFrame(word_freq_list, columns=['Word', 'Frequency'])\n",
    "\n",
    "        # Replace words with frequency less than threshold with '<unk>'\n",
    "        word_freq_df['Word'] = word_freq_df.apply(\n",
    "            lambda row: self.unknown_token if row['Frequency'] <= self.threshold else row['Word'], \n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # Group by 'Word' and aggregate by sum\n",
    "        word_freq_df = word_freq_df.groupby('Word', as_index=False)['Frequency'].agg('sum')\n",
    "\n",
    "        # Sort the DataFrame by frequency\n",
    "        word_freq_df = word_freq_df.sort_values(by='Frequency', ascending=False, ignore_index=True)\n",
    "\n",
    "        # Add an index column\n",
    "        word_freq_df['Index'] = range(len(word_freq_df))\n",
    "\n",
    "        if self._save:\n",
    "            self.save_vocab(word_freq_df, self.path)\n",
    "\n",
    "        return word_freq_df\n",
    "    \n",
    "    def save_vocab(self, word_freq_df, path):\n",
    "        \"\"\"Write your vocabulary to the file\"\"\"\n",
    "        if not os.path.exists(os.path.dirname(path)):\n",
    "            os.makedirs(os.path.dirname(path))\n",
    "\n",
    "        with open(path, 'w') as file:\n",
    "            vocabulary = word_freq_df.to_records(index=False)\n",
    "            for word, frequency, index in vocabulary:\n",
    "                file.write(f'{word}\\t{index}\\t{frequency}\\n')\n",
    "\n",
    "\n",
    "df = pd.read_json(os.path.join(PathConfig.DATA_PATH, \"train.json\"))\n",
    "\n",
    "vocab_generator = VocabularyGenerator(threshold=3, unknown_token=\"<unk>\", save=False)\n",
    "vocab_df = vocab_generator.generate_vocabulary(df, \"sentence\")\n",
    "vocab_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38218, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sentence</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[Pierre, Vinken, ,, 61, years, old, ,, will, j...</td>\n",
       "      <td>[NNP, NNP, ,, CD, NNS, JJ, ,, MD, VB, DT, NN, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[Mr., Vinken, is, chairman, of, Elsevier, N.V....</td>\n",
       "      <td>[NNP, NNP, VBZ, NN, IN, NNP, NNP, ,, DT, NNP, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[Rudolph, Agnew, ,, 55, years, old, and, forme...</td>\n",
       "      <td>[NNP, NNP, ,, CD, NNS, JJ, CC, JJ, NN, IN, NNP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[A, form, of, asbestos, once, used, to, make, ...</td>\n",
       "      <td>[DT, NN, IN, NN, RB, VBN, TO, VB, NNP, NN, NNS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[The, asbestos, fiber, ,, crocidolite, ,, is, ...</td>\n",
       "      <td>[DT, NN, NN, ,, NN, ,, VBZ, RB, JJ, IN, PRP, V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>[Lorillard, Inc., ,, the, unit, of, New, York-...</td>\n",
       "      <td>[NNP, NNP, ,, DT, NN, IN, JJ, JJ, NNP, NNP, WD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>[Although, preliminary, findings, were, report...</td>\n",
       "      <td>[IN, JJ, NNS, VBD, VBN, RBR, IN, DT, NN, IN, ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>[A, Lorillard, spokewoman, said, ,, ``, This, ...</td>\n",
       "      <td>[DT, NNP, NN, VBD, ,, ``, DT, VBZ, DT, JJ, NN, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>[We, 're, talking, about, years, ago, before, ...</td>\n",
       "      <td>[PRP, VBP, VBG, IN, NNS, IN, IN, NN, VBD, IN, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>[There, is, no, asbestos, in, our, products, n...</td>\n",
       "      <td>[EX, VBZ, DT, NN, IN, PRP$, NNS, RB, ., '']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                           sentence  \\\n",
       "0      0  [Pierre, Vinken, ,, 61, years, old, ,, will, j...   \n",
       "1      1  [Mr., Vinken, is, chairman, of, Elsevier, N.V....   \n",
       "2      2  [Rudolph, Agnew, ,, 55, years, old, and, forme...   \n",
       "3      3  [A, form, of, asbestos, once, used, to, make, ...   \n",
       "4      4  [The, asbestos, fiber, ,, crocidolite, ,, is, ...   \n",
       "5      5  [Lorillard, Inc., ,, the, unit, of, New, York-...   \n",
       "6      6  [Although, preliminary, findings, were, report...   \n",
       "7      7  [A, Lorillard, spokewoman, said, ,, ``, This, ...   \n",
       "8      8  [We, 're, talking, about, years, ago, before, ...   \n",
       "9      9  [There, is, no, asbestos, in, our, products, n...   \n",
       "\n",
       "                                              labels  \n",
       "0  [NNP, NNP, ,, CD, NNS, JJ, ,, MD, VB, DT, NN, ...  \n",
       "1  [NNP, NNP, VBZ, NN, IN, NNP, NNP, ,, DT, NNP, ...  \n",
       "2  [NNP, NNP, ,, CD, NNS, JJ, CC, JJ, NN, IN, NNP...  \n",
       "3  [DT, NN, IN, NN, RB, VBN, TO, VB, NNP, NN, NNS...  \n",
       "4  [DT, NN, NN, ,, NN, ,, VBZ, RB, JJ, IN, PRP, V...  \n",
       "5  [NNP, NNP, ,, DT, NN, IN, JJ, JJ, NNP, NNP, WD...  \n",
       "6  [IN, JJ, NNS, VBD, VBN, RBR, IN, DT, NN, IN, ,...  \n",
       "7  [DT, NNP, NN, VBD, ,, ``, DT, VBZ, DT, JJ, NN, .]  \n",
       "8  [PRP, VBP, VBG, IN, NNS, IN, IN, NN, VBD, IN, ...  \n",
       "9        [EX, VBZ, DT, NN, IN, PRP$, NNS, RB, ., '']  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.05 s (started: 2023-09-22 01:44:32 -07:00)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(os.path.join(PathConfig.DATA_PATH, \"train.json\"))\n",
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>,</td>\n",
       "      <td>46476</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>42044</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>39533</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.</td>\n",
       "      <td>37452</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of</td>\n",
       "      <td>22104</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>to</td>\n",
       "      <td>21305</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a</td>\n",
       "      <td>18469</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>and</td>\n",
       "      <td>15346</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>in</td>\n",
       "      <td>14609</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>'s</td>\n",
       "      <td>8872</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Word  Frequency  Index\n",
       "0      ,      46476      0\n",
       "1  <unk>      42044      1\n",
       "2    the      39533      2\n",
       "3      .      37452      3\n",
       "4     of      22104      4\n",
       "5     to      21305      5\n",
       "6      a      18469      6\n",
       "7    and      15346      7\n",
       "8     in      14609      8\n",
       "9     's       8872      9"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.42 s (started: 2023-09-22 01:44:18 -07:00)\n"
     ]
    }
   ],
   "source": [
    "word_freq = df['sentence'].apply(lambda sentence: Counter(sentence))\n",
    "\n",
    "# Initialize an empty counter\n",
    "combined_counter = Counter()\n",
    "\n",
    "# Loop through each counter and update the combined counter\n",
    "for counter in word_freq:\n",
    "    combined_counter.update(counter)\n",
    "\n",
    "# Convert combined_counter to a list of tuples (word, frequency)\n",
    "word_freq_list = list(combined_counter.items())\n",
    "\n",
    "# Create a DataFrame\n",
    "word_freq_df = pd.DataFrame(word_freq_list, columns=['Word', 'Frequency'])\n",
    "\n",
    "# Replace words with frequency less than threshold with '<unk>'\n",
    "word_freq_df['Word'] = word_freq_df.apply(\n",
    "    lambda row: VocabConfig.UNKNOWN_TOKEN if row['Frequency'] <= VocabConfig.THRESHOLD else row['Word'], \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Group by 'Word' and aggregate by sum\n",
    "word_freq_df = word_freq_df.groupby('Word', as_index=False)['Frequency'].agg('sum')\n",
    "# Sort the DataFrame by frequency\n",
    "\n",
    "word_freq_df = word_freq_df.sort_values(by='Frequency', ascending=False, ignore_index=True)\n",
    "# Add an index column\n",
    "word_freq_df['Index'] = range(len(word_freq_df))\n",
    "word_freq_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 187 ms (started: 2023-09-22 01:34:23 -07:00)\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(os.path.dirname(PathConfig.VOCAB_FILE_PATH)):\n",
    "    os.makedirs(os.path.dirname(PathConfig.VOCAB_FILE_PATH))\n",
    "\n",
    "with open(PathConfig.VOCAB_FILE_PATH, 'w') as file:\n",
    "    # Write your vocabulary to the file\n",
    "    # Assuming you have a method that returns the vocabulary\n",
    "    vocabulary = word_freq_df.to_records(index=False)\n",
    "    for word, frequency, index in vocabulary:\n",
    "        file.write(f'{word}\\t{index}\\t{frequency}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Model Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Greedy Decoding with HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Viterbi Decoding with HMM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSCI544",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
