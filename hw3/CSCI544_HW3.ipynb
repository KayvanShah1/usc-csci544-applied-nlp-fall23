{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1R13SCmf3x-uc2w3ZDKeHETwGxMmz2_z1",
      "authorship_tag": "ABX9TyM12nU2D7Hu/kNupy7hI3s5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KayvanShah1/usc-csci-544-assignments-hw/blob/main/hw3/CSCI544_HW3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencies"
      ],
      "metadata": {
        "id": "5wMrhc8a_EjX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install"
      ],
      "metadata": {
        "id": "ChxDjnRnEJTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions\n",
        "!pip install ipython-autotime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0OaIevOB4ey",
        "outputId": "9d7bcbd6-c78b-4fb3-c2e8-a309f63dfc14"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.10/dist-packages (0.1.73)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.10/dist-packages (from contractions) (0.0.24)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.10/dist-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.10/dist-packages (from textsearch>=0.0.21->contractions) (2.0.0)\n",
            "Requirement already satisfied: ipython-autotime in /usr/local/lib/python3.10/dist-packages (0.3.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ipython-autotime) (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ipython-autotime) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.8)\n",
            "Requirement already satisfied: contractions in /usr/local/lib/python3.10/dist-packages (0.1.73)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.10/dist-packages (from contractions) (0.0.24)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.10/dist-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.10/dist-packages (from textsearch>=0.0.21->contractions) (2.0.0)\n",
            "Requirement already satisfied: ipython-autotime in /usr/local/lib/python3.10/dist-packages (0.3.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ipython-autotime) (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ipython-autotime) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.8)\n",
            "time: 33.1 s (started: 2023-10-14 05:54:27 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "B-sgJC0wEGqF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7kG4_ic-tfe",
        "outputId": "35e780e0-813f-4c05-fa68-109206982975"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autotime extension is already loaded. To reload it, use:\n",
            "  %reload_ext autotime\n",
            "time: 457 ms (started: 2023-10-14 08:28:45 +00:00)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import unicodedata\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
        "\n",
        "import contractions\n",
        "\n",
        "import gensim\n",
        "import gensim.downloader as api\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config"
      ],
      "metadata": {
        "id": "MIBlsIzN4H9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/drive/MyDrive/Colab Notebooks/CSCI544/HW3\")\n",
        "\n",
        "class DatasetConfig:\n",
        "    RANDOM_STATE = 34\n",
        "    TEST_SPLIT = 0.2\n",
        "    N_SAMPLES_EACH_CLASS = 50000\n",
        "    DATA_PATH = \"amazon_reviews_us_Office_Products_v1_00.tsv.gz\"\n",
        "    PROCESSED_DATA_PATH = \"amazon_review_preprocessed_sentiment_analysis.csv\"\n",
        "\n",
        "\n",
        "class Word2VecConfig:\n",
        "    PRETRAINED_MODEL = \"word2vec-google-news-300\"\n",
        "    PRETRAINED_MODEL_SAVE_PATH = f\"./{PRETRAINED_MODEL}/{PRETRAINED_MODEL}.gz\"\n",
        "    WINDOW_SIZE = 13\n",
        "    MAX_LENGTH = 300\n",
        "    MIN_WORD_COUNT = 9\n",
        "    CUSTOM_MODEL_PATH = \"word2vec-custom.model\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxX0Bfswxc_4",
        "outputId": "44fea969-b28d-406d-9547-60170d0b6d1c"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.07 ms (started: 2023-10-14 08:52:55 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Preparation"
      ],
      "metadata": {
        "id": "1lUVynXQ38dL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read and Process"
      ],
      "metadata": {
        "id": "sqe3kdXz4f2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LoadData:\n",
        "    @staticmethod\n",
        "    def load_data(path):\n",
        "        df = pd.read_csv(\n",
        "            path,\n",
        "            sep=\"\\t\",\n",
        "            usecols=[\"review_headline\", \"review_body\", \"star_rating\"],\n",
        "            on_bad_lines=\"skip\",\n",
        "            memory_map=True,\n",
        "        )\n",
        "        return df\n",
        "\n",
        "\n",
        "class ProcessData:\n",
        "    @staticmethod\n",
        "    def filter_columns(df):\n",
        "        return df.loc[:, [\"review_body\", \"star_rating\"]]\n",
        "\n",
        "    @staticmethod\n",
        "    def convert_star_rating(df):\n",
        "        df[\"star_rating\"] = pd.to_numeric(df[\"star_rating\"], errors=\"coerce\")\n",
        "        df.dropna(subset=[\"star_rating\"], inplace=True)\n",
        "        return df\n",
        "\n",
        "    @staticmethod\n",
        "    def classify_sentiment(df):\n",
        "        df[\"sentiment\"] = df[\"star_rating\"].apply(lambda x: 1 if x <= 3 else 2)\n",
        "        return df\n",
        "\n",
        "    @staticmethod\n",
        "    def sample_data(df, n_samples, random_state):\n",
        "        sampled_df = pd.concat(\n",
        "            [\n",
        "                df.query(\"sentiment==1\").sample(n=n_samples, random_state=random_state),\n",
        "                df.query(\"sentiment==2\").sample(n=n_samples, random_state=random_state),\n",
        "            ],\n",
        "            ignore_index=True,\n",
        "        ).sample(frac=1, random_state=random_state, ignore_index=True)\n",
        "\n",
        "        sampled_df.drop(columns=[\"star_rating\"], inplace=True)\n",
        "        return sampled_df\n",
        "\n",
        "\n",
        "class CleanText:\n",
        "    @staticmethod\n",
        "    def unicode_to_ascii(s):\n",
        "        return \"\".join(\n",
        "            c for c in unicodedata.normalize(\"NFD\", s) if unicodedata.category(c) != \"Mn\"\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def expand_contractions(text):\n",
        "        return contractions.fix(text)\n",
        "\n",
        "    @staticmethod\n",
        "    def remove_email_addresses(text):\n",
        "        return re.sub(r\"[a-zA-Z0-9_\\-\\.]+@[a-zA-Z0-9_\\-\\.]+\\.[a-zA-Z]{2,5}\", \"\", text)\n",
        "\n",
        "    @staticmethod\n",
        "    def remove_urls(text):\n",
        "        return re.sub(r\"\\bhttps?:\\/\\/\\S+|www\\.\\S+\", \"\", text)\n",
        "\n",
        "    @staticmethod\n",
        "    def remove_html_tags(text):\n",
        "        return re.sub(r\"<.*?>\", \"\", text)\n",
        "\n",
        "    @staticmethod\n",
        "    def clean_text(text):\n",
        "        text = CleanText.unicode_to_ascii(text.lower().strip())\n",
        "\n",
        "        # replacing email addresses with empty string\n",
        "        # text = CleanText.remove_email_addresses(text)\n",
        "\n",
        "        # replacing urls with empty string\n",
        "        # text = CleanText.remove_urls(text)\n",
        "\n",
        "        # Remove HTML tags\n",
        "        text = CleanText.remove_html_tags(text)\n",
        "\n",
        "        # Expand contraction for eg., wouldn't => would not\n",
        "        text = CleanText.expand_contractions(text)\n",
        "\n",
        "        # creating a space between a word and the punctuation following it\n",
        "        text = re.sub(r\"([?.!,¿])\", r\" \\1 \", text)\n",
        "        text = re.sub(r'[\" \"]+', \" \", text)\n",
        "\n",
        "        # removes all non-alphabetical characters\n",
        "        # text = re.sub(r\"[^a-zA-Z\\s]+\", \"\", text)\n",
        "\n",
        "        # remove extra spaces\n",
        "        # text = re.sub(\" +\", \" \", text)\n",
        "        text = text.strip()\n",
        "        return text\n",
        "\n",
        "\n",
        "class PreprocessText:\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    @staticmethod\n",
        "    def get_stopwords_pattern():\n",
        "        # Stopword list\n",
        "        og_stopwords = set(stopwords.words(\"english\"))\n",
        "\n",
        "        # Define a list of negative words to remove\n",
        "        neg_words = [\"no\", \"not\", \"nor\", \"neither\", \"none\", \"never\", \"nobody\", \"nowhere\"]\n",
        "        custom_stopwords = [word for word in og_stopwords if word not in neg_words]\n",
        "        pattern = re.compile(r\"\\b(\" + r\"|\".join(og_stopwords) + r\")\\b\\s*\")\n",
        "        return pattern\n",
        "\n",
        "    @staticmethod\n",
        "    def pos_tagger(tag):\n",
        "        if tag.startswith(\"J\"):\n",
        "            return wordnet.ADJ\n",
        "        elif tag.startswith(\"V\"):\n",
        "            return wordnet.VERB\n",
        "        elif tag.startswith(\"N\"):\n",
        "            return wordnet.NOUN\n",
        "        elif tag.startswith(\"R\"):\n",
        "            return wordnet.ADV\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    @staticmethod\n",
        "    def lemmatize_text_using_pos_tags(text):\n",
        "        words = nltk.pos_tag(word_tokenize(text))\n",
        "        words = map(lambda x: (x[0], PreprocessText.pos_tagger(x[1])), words)\n",
        "        lemmatized_words = [\n",
        "            PreprocessText.lemmatizer.lemmatize(word, tag) if tag else word for word, tag in words\n",
        "        ]\n",
        "        return \" \".join(lemmatized_words)\n",
        "\n",
        "    @staticmethod\n",
        "    def lemmatize_text(text):\n",
        "        words = word_tokenize(text)\n",
        "        lemmatized_words = [PreprocessText.lemmatizer.lemmatize(word) for word in words]\n",
        "        return \" \".join(lemmatized_words)\n",
        "\n",
        "    pattern = get_stopwords_pattern()\n",
        "\n",
        "    @staticmethod\n",
        "    def preprocess_text(text):\n",
        "        # replacing all the stopwords\n",
        "        # text = PreprocessText.pattern.sub(\"\", text)\n",
        "        # text = PreprocessText.lemmatize_text(text)\n",
        "        return text\n",
        "\n",
        "\n",
        "clean_text_vect = np.vectorize(CleanText.clean_text)\n",
        "preprocess_text_vect = np.vectorize(PreprocessText.preprocess_text)\n",
        "\n",
        "\n",
        "def clean_and_process_data(path):\n",
        "    df = LoadData.load_data(path)\n",
        "    df_filtered = ProcessData.filter_columns(df)\n",
        "    df_filtered = ProcessData.convert_star_rating(df_filtered)\n",
        "    df_filtered = ProcessData.classify_sentiment(df_filtered)\n",
        "\n",
        "    balanced_df = ProcessData.sample_data(\n",
        "        df_filtered, DatasetConfig.N_SAMPLES_EACH_CLASS, DatasetConfig.RANDOM_STATE\n",
        "    )\n",
        "\n",
        "    balanced_df[\"review_body\"] = balanced_df[\"review_body\"].astype(str)\n",
        "\n",
        "    # Clean data\n",
        "    # avg_len_before_clean = balanced_df[\"review_body\"].apply(len).mean()\n",
        "    balanced_df[\"review_body\"] = balanced_df[\"review_body\"].apply(clean_text_vect)\n",
        "    # Drop reviews that are empty\n",
        "    balanced_df = balanced_df.loc[balanced_df[\"review_body\"].str.strip() != \"\"]\n",
        "    # avg_len_after_clean = balanced_df[\"review_body\"].apply(len).mean()\n",
        "\n",
        "    # Preprocess data\n",
        "    # avg_len_before_preprocess = avg_len_after_clean\n",
        "    # balanced_df[\"review_body\"] = balanced_df[\"review_body\"].apply(preprocess_text_vect)\n",
        "    # avg_len_after_preprocess = balanced_df[\"review_body\"].apply(len).mean()\n",
        "\n",
        "    # Print Results\n",
        "    # print(f\"{avg_len_before_clean:.2f}, {avg_len_after_clean:.2f}\")\n",
        "    # print(f\"{avg_len_before_preprocess:.2f}, {avg_len_after_preprocess:.2f}\")\n",
        "    return balanced_df\n",
        "\n",
        "\n",
        "def get_reviews_dataset(new=False):\n",
        "    if new or not os.path.exists(DatasetConfig.DATA_PATH):\n",
        "        balanced_df = clean_and_process_data(DatasetConfig.DATA_PATH)\n",
        "        balanced_df.to_csv(DatasetConfig.PROCESSED_DATA_PATH, index=False)\n",
        "    else:\n",
        "        balanced_df = pd.read_csv(DatasetConfig.PROCESSED_DATA_PATH)\n",
        "    return balanced_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTuRzMHtIlx0",
        "outputId": "ab0dbe11-27e9-4bf6-a88c-f8e0e6ca2cf6"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 4.94 ms (started: 2023-10-14 07:04:57 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_df = get_reviews_dataset(new=False)\n",
        "balanced_df.dropna(inplace=True)\n",
        "print(\"Total Records:\", balanced_df.shape)\n",
        "balanced_df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "CwsDbNoi_1Oc",
        "outputId": "584eab82-1e01-4726-c119-7c24e10a290c"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Records: (99998, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         review_body  sentiment\n",
              "0  i set up a photo booth at my sister's wedding ...          2\n",
              "1  like everyone else , i like saving money , so ...          1\n",
              "2  the pen is perfect what i want ! however the i...          2\n",
              "3  i think they are too expensive for their quali...          1\n",
              "4  black is working wonderfully , and both cartri...          1\n",
              "5  i have problems with the moveable tab ! it see...          1\n",
              "6  this printer sucks ! it started out working wo...          1\n",
              "7  the ink on these cartridges leak . i would ret...          1\n",
              "8  it gets points for working as designed; from w...          2\n",
              "9  i ordered these and they work just fine , but ...          1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-61bc67ea-efec-425f-84bf-8e51cbf26531\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_body</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i set up a photo booth at my sister's wedding ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>like everyone else , i like saving money , so ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the pen is perfect what i want ! however the i...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i think they are too expensive for their quali...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>black is working wonderfully , and both cartri...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>i have problems with the moveable tab ! it see...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>this printer sucks ! it started out working wo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>the ink on these cartridges leak . i would ret...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>it gets points for working as designed; from w...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>i ordered these and they work just fine , but ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61bc67ea-efec-425f-84bf-8e51cbf26531')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-61bc67ea-efec-425f-84bf-8e51cbf26531 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-61bc67ea-efec-425f-84bf-8e51cbf26531');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9e543a94-2a00-4502-bfc6-d86f9e889bfe\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9e543a94-2a00-4502-bfc6-d86f9e889bfe')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9e543a94-2a00-4502-bfc6-d86f9e889bfe button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 77
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 963 ms (started: 2023-10-14 08:38:41 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a PyTorch Dataset"
      ],
      "metadata": {
        "id": "0TmoyiGlSh8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AmazonReviewsSentimentDataset(Dataset):\n",
        "    def __init__(self, df, word2vec_model):\n",
        "        self.data = df\n",
        "        self.word2vec_model = word2vec_model\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx >= self.__len__:\n",
        "            raise IndexError\n",
        "\n",
        "        text = self.data.iloc[idx]['review_body']\n",
        "        text = word_tokenize(text)\n",
        "\n",
        "        label = self.data.iloc[idx]['sentiment']\n",
        "\n",
        "        # Retrieve word embeddings\n",
        "        embeddings = [self.word2vec_model[word] for word in text if word in self.word2vec_model]\n",
        "        embeddings = np.mean(embeddings, axis=0)\n",
        "\n",
        "        return {\n",
        "            \"embeddings\": torch.tensor(embeddings, dtype=torch.long),\n",
        "            \"target\":  torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flCZXZDWSmw8",
        "outputId": "0fdc235d-7f9e-4f65-936e-b3024f244491"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.42 ms (started: 2023-10-14 07:57:07 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and Test Spilts"
      ],
      "metadata": {
        "id": "REP4Ohx2MfFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = train_test_split(\n",
        "    balanced_df,\n",
        "    test_size=DatasetConfig.TEST_SPLIT,\n",
        "    random_state=DatasetConfig.RANDOM_STATE,\n",
        "    stratify=balanced_df[\"sentiment\"]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eppCI8v4IO8p",
        "outputId": "2f247dff-ffc6-4c3a-e1c4-54dec9c8c01d"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 93.2 ms (started: 2023-10-14 08:39:00 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Embedding\n",
        "- Run the `api.load()` once and copied the model from temporary path to local drive for fast loading of model in memory.\n",
        "\n",
        "### References:\n",
        "1. [Faster way to load word2vec model](https://github.com/RaRe-Technologies/gensim/issues/2642)\n",
        "2. [Tutorial](https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html#sphx-glr-auto-examples-tutorials-run-word2vec-py)"
      ],
      "metadata": {
        "id": "01xZp5gDGS3Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download & Save Word2Vec pretrained model"
      ],
      "metadata": {
        "id": "JkazcqCJ74yp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy model to current directory\n",
        "# !mkdir word2vec-google-news-300\n",
        "# !cp /root/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz ./word2vec-google-news-300"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCelyroFLCQ_",
        "outputId": "7962711a-9c09-43cf-e66a-70e139c2c368"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 14.8 s (started: 2023-10-14 06:03:02 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_pretrained_model():\n",
        "    if not os.path.exists(Word2VecConfig.PRETRAINED_MODEL_SAVE_PATH):\n",
        "        pretrained_model = api.load(Word2VecConfig.PRETRAINED_MODEL, return_path=True)\n",
        "    else:\n",
        "        pretrained_model = gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(\n",
        "            Word2VecConfig.PRETRAINED_MODEL_SAVE_PATH, binary=True\n",
        "        )\n",
        "    return pretrained_model\n",
        "\n",
        "pretrained_model = load_pretrained_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dbn_i8DeS_H5",
        "outputId": "94d75151-80ca-4a48-8ba3-628d0fab82d3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1min 17s (started: 2023-10-14 06:15:55 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Semantic similarity examples"
      ],
      "metadata": {
        "id": "cz6qCPYqGSVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 1: King - Man + Woman = Queen\n",
        "result = pretrained_model.most_similar(positive=['woman', 'king'], negative=['man'])\n",
        "print(f\"Semantic Similarity: {result[0][0]}\")\n",
        "\n",
        "# Example 2: excellent ~ outstanding\n",
        "result = pretrained_model.similarity('excellent', 'outstanding')\n",
        "print(f\"Semantic Similarity: {result}\")\n",
        "\n",
        "# Example 3: Paris - France + Italy = Milan\n",
        "result = pretrained_model.most_similar(positive=['Italy', 'Paris'], negative=['France'])\n",
        "print(f\"Semantic Similarity: {result[0][0]}\")\n",
        "\n",
        "# Example 4: Car - Wheel + Boat = Yacht\n",
        "result = pretrained_model.most_similar(positive=['Boat', 'Car'], negative=['Wheel'])\n",
        "print(f\"Semantic Similarity: {result[0][0]}\")\n",
        "\n",
        "# Example 5: Delicious ~ Tasty\n",
        "result = pretrained_model.similarity('Delicious', 'Tasty')\n",
        "print(f\"Semantic Similarity: {result}\")\n",
        "\n",
        "# Example 6: Computer ~ Plant\n",
        "result = pretrained_model.similarity('Computer', 'Plant')\n",
        "print(f\"Semantic Similarity: {result}\")\n",
        "\n",
        "# Example 7: Cat ~ Dog\n",
        "result = pretrained_model.similarity('Cat', 'Dog')\n",
        "print(f\"Semantic Similarity: {result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUXIBxdPyOsP",
        "outputId": "f09f119d-13db-46d7-e175-7fdf477b5a24"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Semantic Similarity: queen\n",
            "Semantic Similarity: 0.5567485690116882\n",
            "Semantic Similarity: Milan\n",
            "Semantic Similarity: Yacht\n",
            "Semantic Similarity: 0.5718502402305603\n",
            "Semantic Similarity: 0.04445184767246246\n",
            "Semantic Similarity: 0.6061107516288757\n",
            "time: 2.9 s (started: 2023-10-14 07:42:09 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Word2Vec Embeddings Generation"
      ],
      "metadata": {
        "id": "Gbe7-WOzOitC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = train_df[\"review_body\"].apply(word_tokenize)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLiFYOglUru7",
        "outputId": "0cfae6d4-aefa-4480-e2d1-2b29330f0196"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 56.5 s (started: 2023-10-14 08:39:06 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Word2Vec model\n",
        "w2v_model_custom = Word2Vec(\n",
        "    sentences=sentences,\n",
        "    vector_size=Word2VecConfig.MAX_LENGTH,\n",
        "    window=Word2VecConfig.WINDOW_SIZE,\n",
        "    min_count=Word2VecConfig.MIN_WORD_COUNT\n",
        ")\n",
        "\n",
        "# Save the model\n",
        "w2v_model_custom.save(Word2VecConfig.CUSTOM_MODEL_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHA1YeIJPjIz",
        "outputId": "ffa07c9b-ae09-4992-8264-09685a8c92b5"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1min 20s (started: 2023-10-14 08:42:08 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Custom Embeddings"
      ],
      "metadata": {
        "id": "dnPj5ypZWiw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the custom model\n",
        "w2v_model_custom = Word2Vec.load(Word2VecConfig.CUSTOM_MODEL_PATH)\n",
        "\n",
        "# Example 1: King - Man + Woman = Queen\n",
        "res = w2v_model_custom.wv.most_similar(positive=['woman', 'king'], negative=['man'])\n",
        "print(f\"Semantic Similarity (Custom Model): {res[0]}\")\n",
        "\n",
        "# Example 2: excellent ~ outstanding\n",
        "res = w2v_model_custom.wv.similarity('excellent', 'outstanding')\n",
        "print(f\"Semantic Similarity (Custom Model): {res}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IFM8OadWmtl",
        "outputId": "b091b1a9-874d-4aef-b056-46a74160546f"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Semantic Similarity (Custom Model): ('queen', 0.5496216416358948)\n",
            "Semantic Similarity (Custom Model): 0.7910025715827942\n",
            "time: 140 ms (started: 2023-10-14 08:43:50 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Models"
      ],
      "metadata": {
        "id": "1YrcemHfPoZQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feedforward Neural Networks"
      ],
      "metadata": {
        "id": "pkwLebfVPqz5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recurrent Neural Networks"
      ],
      "metadata": {
        "id": "QKbIuQCOPviZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# End of File"
      ],
      "metadata": {
        "id": "S8L4NH6ROfwQ"
      }
    }
  ]
}